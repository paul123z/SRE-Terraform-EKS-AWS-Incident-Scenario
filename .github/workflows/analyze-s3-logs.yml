name: Analyze S3 Logs with Bedrock

on:
  workflow_dispatch:
    inputs:
      s3_object_url:
        description: 'S3 Object URL (e.g., https://bucket.s3.region.amazonaws.com/path/to/log.log)'
        required: true
        type: string

jobs:
  analyze-logs:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: us-west-1  # Bedrock region
        
    - name: Install dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y jq curl unzip
        
    - name: Install AWS CLI v2
      run: |
        # Check if AWS CLI is already installed
        if command -v aws &> /dev/null; then
          echo "AWS CLI is already installed:"
          aws --version
        else
          echo "Installing AWS CLI v2..."
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "awscliv2.zip"
          unzip awscliv2.zip
          sudo ./aws/install --update
        fi
        
    - name: Verify AWS CLI and Bedrock access
      run: |
        echo "Testing AWS CLI installation..."
        aws --version
        
        echo "Testing Bedrock access..."
        aws bedrock list-foundation-models --region us-west-1 --query 'modelSummaries[?providerName==`Anthropic`]' --output table
        
    - name: Extract S3 bucket and key from URL
      id: s3-info
      run: |
        # Parse S3 URL to extract bucket and key
        S3_URL="${{ github.event.inputs.s3_object_url }}"
        
        # Handle different URL formats
        if [[ "$S3_URL" == s3://* ]]; then
          # s3://bucket/key format
          BUCKET=$(echo "$S3_URL" | sed 's|s3://||' | cut -d'/' -f1)
          KEY=$(echo "$S3_URL" | sed 's|s3://[^/]*/||')
        elif [[ "$S3_URL" == https://*.s3.*.amazonaws.com/* ]]; then
          # https://bucket.s3.region.amazonaws.com/key format
          BUCKET=$(echo "$S3_URL" | sed 's|https://||' | cut -d'.' -f1)
          KEY=$(echo "$S3_URL" | sed 's|https://[^/]*/||')
        else
          echo "Error: Invalid S3 URL format. Please use s3://bucket/key or https://bucket.s3.region.amazonaws.com/key"
          exit 1
        fi
        
        echo "Extracted bucket: $BUCKET"
        echo "Extracted key: $KEY"
        
        # Set outputs for next steps
        echo "bucket=$BUCKET" >> $GITHUB_OUTPUT
        echo "key=$KEY" >> $GITHUB_OUTPUT
        
    - name: Download log file from S3
      run: |
        echo "Downloading log file from S3..."
        aws s3 cp "s3://${{ steps.s3-info.outputs.bucket }}/${{ steps.s3-info.outputs.key }}" ./incident-log.log
        
        echo "Log file size: $(wc -c < incident-log.log) bytes"
        echo "Log file preview (first 500 characters):"
        head -c 500 incident-log.log
        
    - name: Copy analysis script
      run: |
        cp .github/analyze-s3-logs-script.sh ./analyze-log.sh
        chmod +x analyze-log.sh
        
    - name: Run analysis
      run: |
        ./analyze-log.sh
        
    - name: Upload analysis results as artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: analysis-results
        path: |
          bedrock-response.json
          incident-log.log
          analysis-results.txt
        retention-days: 7
